{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import cv2 for reading the image in tif format\n",
    "import cv2\n",
    "import keras as k\n",
    "images = []\n",
    "train_img = []\n",
    "test_img = []\n",
    "train_lab = []\n",
    "#keras model is imported for constructing the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import accuracy_score\n",
    "#speciy the path to get the tags for corresponding image. The file is in csv(Comma Separated value) file\n",
    "df_train = pd.read_csv('F:/Sample/sample1.csv')\n",
    "#getting all possible labels once\n",
    "#Declaring the array to store the labels.\n",
    "\n",
    "possible_labels=[]\n",
    "#for each row in the csv file, the tags are seperated with space(' ').\n",
    "#Keeping this as delimiter, storing the all unique tags only once in possible labels\n",
    "for z in df_train['tags'].values:\n",
    "    a=z.split(' ')\n",
    "    possible_labels=list(set(possible_labels)|set(a))\n",
    "possible_labels=sorted(possible_labels)\n",
    "print(possible_labels)\n",
    "#Reading the images and converting to array of pixel vakues\n",
    "#store the image pixel values in the array.\n",
    "k=0;\n",
    "for f,tags in zip(df_train['image_name'].values,df_train['tags']):\n",
    "    images = cv2.imread('F:/Sample/sample_50/{}.tif'.format(f))\n",
    "#Creating an array of 17 zeros, this our dataset contains only 17 unique labels.\n",
    "    label_array = np.zeros(17)\n",
    "#Now for each image, the corresponding image label's index is set.\n",
    "#for example first image contains tags as primary and haze.\n",
    "# taking first zero label array consisting of 17 zeros is now made to 1 in primary index and haze index only\n",
    "#Rest of the index in array is left as 0.\n",
    "    for t in tags.split(' '):\n",
    "        label_array[possible_labels.index(t)] = 1\n",
    "\n",
    "    print('Image ',k,':',label_array)\n",
    "    k+=1\n",
    "#images are resized to 32*32.\n",
    "    train_img.append(cv2.resize(images, (32, 32)))\n",
    "    train_lab.append(label_array)\n",
    "\n",
    "\n",
    "#Setting the datatype for labels as unsigned 8 bit.\n",
    "print(train_lab)\n",
    "train_lab = np.array(train_lab, np.uint8)\n",
    "print('array')\n",
    "print(train_lab)\n",
    "#Setting the datatype for labels as float 16 bit.\n",
    "print(train_img)\n",
    "train_img = np.array(train_img, np.float16) / 255.\n",
    "print(train_img)\n",
    "print(train_lab)\n",
    "split = 32384 #(80% of total dataset)\n",
    "#Dividing the testing and training data using split variable\n",
    "train_img, test_img, train_lab, test_lab = train_img[:split], train_img[split:], train_lab[:split], train_lab[split:]\n",
    "print(test_img)\n",
    "print(test_lab)\n",
    "\n",
    "#Constructing the model using sequential (as the data is sent as input to the next layer).\n",
    "cnn_net = Sequential()\n",
    "#Adding layers to the network\n",
    "#Filters :32 (number output of filters in the convolution)\n",
    "#kernel_size :3*3(specifying the width and height of the 2D convolution window).\n",
    "#input_shape :(32,32,3)Dimension of the input image and channels\n",
    "#Activation :relu (A(x) = max(0,x)) to restrict the value in a range that produces the output from the layer.\n",
    "cnn_net.add(Conv2D(32, kernel_size=(3, 3),\n",
    "activation='relu',\n",
    "input_shape=(32, 32, 3)))\n",
    "#Activation is relu in order to remove negative values.\n",
    "cnn_net.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#To reduce the dimension of the previous layer by taking a stride of 2*2 with maximum value.\n",
    "#Pool_size: 2*2 window within which the maximum value is picked.\n",
    "cnn_net.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#Dropout is used to eliminate overfitting condition.Dropout randomly drops the neurons from activating\n",
    "\n",
    "cnn_net.add(Dropout(0.25))\n",
    "#To produce the one dimensional array of the values from the previous layer.\n",
    "cnn_net.add(Flatten())\n",
    "cnn_net.add(Dense(128, activation='relu'))\n",
    "cnn_net.add(Dropout(0.5))\n",
    "#sigmoid function is used to extract the features for small cahnge in X-axis.\n",
    "#Dense Layer: It is fully connected layer that decides the class based on pattern that has matched so far and the pattern is received from the previous layer.\n",
    "cnn_net.add(Dense(17, activation='sigmoid'))\n",
    "#ADAM:Adam which is Adaptive Moment is used instead of gradient descent\n",
    "#because ADAM has a learning rate for each weight\n",
    "#whereas gradient descent has a single learning rate for all the weights.\n",
    "#BINARY_CROSSENTROPY:This is used because a label of 0 or 1(prediction) is given to each and very label.\n",
    "#Metrics: This parameter is used to judge the model and provides the information about the model in each epochs.\n",
    "cnn_net.compile(loss='binary_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "#Fitting the model:\n",
    "#Trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "#X: train input images\n",
    "#Y: Corresponding labels\n",
    "#Batch_size: Number of samples taken to train per instance.\n",
    "#Epochs: the number of times to iterate over the training data arrays.\n",
    "#Verbose: To display the progress of epochs with bar\n",
    "#Validation_data: Testing images and testing labels\n",
    "cnn_net.fit(train_img, train_lab,\n",
    "batch_size=128,\n",
    "epochs=4,\n",
    "verbose=1,\n",
    "validation_data=(test_img, test_lab))\n",
    "#Predicting the model:\n",
    "#X: The testing images for prediction.\n",
    "#Batch_size:Number of samples taken to test per instance.\n",
    "pred_test = cnn_net.predict(test_img, batch_size=128)\n",
    "print(test_lab)\n",
    "print(pred_test)\n",
    "#therhold is set to convert the floating numbers to binary values.\n",
    "\n",
    "threshold=0.5\n",
    "pred_test[pred_test>=threshold]=1\n",
    "pred_test[pred_test<threshold]=0\n",
    "print(test_lab,pred_test)\n",
    "#Accuracy is used to know how well the model is developed to predict the testing data.\n",
    "acc=accuracy_score(test_lab,pred_test)\n",
    "print('Accuracy: ',acc*100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
